{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from universalNet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "universalNet(\n",
       "  (input_layer): Layer()\n",
       "  (layer_1): Layer()\n",
       "  (layer_2): Layer()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hparams = {'tau': 1,\n",
    "#            'seed': 42}\n",
    "\n",
    "# params_dict = {'layer_0':\n",
    "#                    {'E':\n",
    "#                         {'n': 7,\n",
    "#                          'projections': {}}},\n",
    "#                'layer_1':\n",
    "#                    {'E':\n",
    "#                         {'n': 100,\n",
    "#                          'bias': False,\n",
    "#                          'activation': 'relu',\n",
    "#                          'projections': \n",
    "#                              {'layer_0':{'E':[]}}}},\n",
    "#                'layer_2':\n",
    "#                    {'E':\n",
    "#                         {'n': 10,\n",
    "#                          'bias': False,\n",
    "#                          'activation': 'relu',\n",
    "#                          'projections':\n",
    "#                              {'layer_1':{'E':[]}}}}\n",
    "#                }\n",
    "\n",
    "# model = universalNet(params_dict, hparams)\n",
    "\n",
    "model = universalNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict(),\n",
       " 'size': 5,\n",
       " 'activation': 'softplus',\n",
       " 'bias_rule': None,\n",
       " 'bias': tensor([0., 0., 0., 0., 0.]),\n",
       " 'learn_bias': False,\n",
       " 'activity': tensor([0., 0., 0., 0., 0.]),\n",
       " 'prev_activity': tensor([0., 0., 0., 0., 0.]),\n",
       " 'activity_history': None,\n",
       " 'state': tensor([0., 0., 0., 0., 0.]),\n",
       " 'projections': {},\n",
       " 'inputs': [Population(), Population()],\n",
       " Population(): Linear(in_features=7, out_features=5, bias=False),\n",
       " Population(): Linear(in_features=7, out_features=5, bias=False)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(model.layer_2.E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('input_layer', Layer()),\n",
       "              ('layer_1', Layer()),\n",
       "              ('layer_2', Layer())])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test forward pass\n",
    "\n",
    "# pattern = torch.rand(7)\n",
    "# model(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
