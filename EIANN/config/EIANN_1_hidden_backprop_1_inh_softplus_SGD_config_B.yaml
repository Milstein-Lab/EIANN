layer_config:
  Input:
    E:
      size: 21
  H1:
    E:
      size: 7
      activation: softplus
      activation_kwargs:
        beta: 99.78563100135408
    FBI:
      size: 1
      activation: softplus
      activation_kwargs:
        beta: 99.78563100135408
  Output:
    E:
      size: 21
      activation: softplus
      activation_kwargs:
        beta: 99.78563100135408
    FBI:
      size: 1
      activation: softplus
      activation_kwargs:
        beta: 99.78563100135408
projection_config:
  H1:
    E:
      Input:
        E:
          weight_init: half_kaining
          weight_bounds: !!python/tuple
          - 0
          - null
          direction: F
          learning_rule: Backprop
      H1:
        FBI:
          weight_init: half_kaining
          weight_bounds: !!python/tuple
          - null
          - 0
          direction: R
          learning_rule: Backprop
    FBI:
      H1:
        E:
          weight_init: fill_
          weight_init_args: !!python/tuple
          - 1
          weight_bounds: !!python/tuple
          - 0
          - null
          direction: F
          learning_rule: Backprop
  Output:
    E:
      H1:
        E:
          weight_init: half_kaining
          weight_bounds: !!python/tuple
          - 0
          - null
          direction: F
          learning_rule: Backprop
      Output:
        FBI:
          weight_init: half_kaining
          weight_bounds: !!python/tuple
          - null
          - 0
          direction: R
          learning_rule: Backprop
    FBI:
      Output:
        E:
          weight_init: fill_
          weight_init_args: !!python/tuple
          - 1
          weight_bounds: !!python/tuple
          - 0
          - null
          direction: F
          learning_rule: Backprop
training_kwargs:
  tau: 3
  forward_steps: 10
  backward_steps: 2
  learning_rate: 9.99980526071132
  verbose: false
  optimizer: SGD
