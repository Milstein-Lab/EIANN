layer_config:
  Input:
    E:
      size: 2
  H1:
    E:
      size: 128
      activation: relu 
      bias_learning_rule: Null
      include_bias: True
  H2:
    E:
      size: 32
      activation: relu
      bias_learning_rule: Null
      include_bias: True
  Output:
    E:
      size: 4
      activation: relu

projection_config:
  H1.E:
    Input.E:
      direction: F
      learning_rule: Backprop

  H2.E:
    H1.E:
      direction: F
      learning_rule: Backprop

  Output.E:
    H2.E:
      direction: F
      learning_rule: Backprop

training_kwargs:
  tau: 1
  forward_steps: 1
  backward_steps: 1
  learning_rate: 0.126449955011941