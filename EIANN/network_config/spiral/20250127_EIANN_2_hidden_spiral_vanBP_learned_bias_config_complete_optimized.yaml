layer_config:
    Input:
        E:
            size: 2
    H1:
        E:
            size: 128
            activation: relu
            include_bias: true
            bias_learning_rule: BackpropBias
            bias_learning_rule_kwargs:
                learning_rate: 0.09062365730598693
    H2:
        E:
            size: 32
            activation: relu
            include_bias: true
            bias_learning_rule: BackpropBias
            bias_learning_rule_kwargs:
                learning_rate: 0.09062365730598693
    Output:
        E:
            size: 4
            activation: relu
            include_bias: true
            bias_learning_rule: BackpropBias
            bias_learning_rule_kwargs:
                learning_rate: 0.06332269100152069
projection_config:
    H1:
        E:
            Input:
                E:
                    weight_init: scaled_kaiming
                    weight_init_args: !!python/tuple
                    - 3.092179371471005
                    direction: F
                    learning_rule: Backprop
                    learning_rule_kwargs:
                        learning_rate: 0.2344242206840233
    H2:
        E:
            H1:
                E:
                    weight_init: scaled_kaiming
                    weight_init_args: !!python/tuple
                    - 1.0684801270167428
                    direction: F
                    learning_rule: Backprop
                    learning_rule_kwargs:
                        learning_rate: 0.2344242206840233
    Output:
        E:
            H2:
                E:
                    weight_init: scaled_kaiming
                    weight_init_args: !!python/tuple
                    - 0.5433568834277912
                    direction: F
                    learning_rule: Backprop
                    learning_rule_kwargs:
                        learning_rate: 0.010809269605442658
training_kwargs:
    tau: 1
    forward_steps: 1
    backward_steps: 1
    learning_rate: 0.2
    verbose: false
    optimizer: SGD