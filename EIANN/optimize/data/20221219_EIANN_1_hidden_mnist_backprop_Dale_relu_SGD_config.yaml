layer_config:
  Input:
    E:
      size: 784
  H1:
    E:
      size: 500
      activation: relu
    FBI:
      size: 14
      activation: relu
      tau: 2
  Output:
    E:
      size: 10
      activation: relu
    FBI:
      size: 1
      activation: relu
      tau: 2
projection_config:
  H1:
    E:
      Input:
        E:
          weight_init: half_kaining
          weight_bounds:
          - 0
          - null
          direction: F
          learning_rule: Backprop
          learning_rule_kwargs:
            learning_rate: 0.22336920149416137
      H1:
        FBI:
          weight_init: half_kaining
          weight_bounds:
          - null
          - 0
          direction: R
          learning_rule: Backprop
          learning_rule_kwargs:
            learning_rate: 0.016298481352946637
    FBI:
      H1:
        E:
          weight_init: half_kaining
          weight_bounds:
          - 0
          - null
          direction: F
          learning_rule: Backprop
          learning_rule_kwargs:
            learning_rate: 0.151980561424801
  Output:
    E:
      H1:
        E:
          weight_init: half_kaining
          weight_bounds:
          - 0
          - null
          direction: F
          learning_rule: Backprop
          learning_rule_kwargs:
            learning_rate: 0.22336920149416137
      Output:
        FBI:
          weight_init: half_kaining
          weight_bounds:
          - null
          - 0
          direction: R
          learning_rule: Backprop
          learning_rule_kwargs:
            learning_rate: 0.016298481352946637
    FBI:
      Output:
        E:
          weight_init: half_kaining
          weight_bounds:
          - 0
          - null
          direction: F
          learning_rule: Backprop
          learning_rule_kwargs:
            learning_rate: 0.151980561424801
training_kwargs:
  tau: 3
  forward_steps: 10
  backward_steps: 3
  learning_rate: 0.2
  verbose: false
  optimizer: SGD
