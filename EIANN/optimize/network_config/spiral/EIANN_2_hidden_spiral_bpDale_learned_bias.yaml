# Modeled on \optimize\network_config\MNIST\20240419_EIANN_2_hidden_mnist_bpDale_relu_SGD_config_F.yaml

layer_config:
  Input: 
    E:
      size: 2

  H1:
    E:
      size: 128
      activation: relu 
      include_bias: True
      bias_learning_rule: Backprop
      bias_learning_rule_kwargs:
        learning_rate: 0.2456298781576449
    SomaI:
      size: 32
      activation: relu

  H2:
    E:
      size: 32
      activation: relu
      include_bias: True 
      bias_learning_rule: Backprop
      bias_learning_rule_kwargs:
        learning_rate: 0.2456298781576449
    SomaI:
      size: 8
      activation: relu

  Output:
    E:
      size: 4
      activation: relu
      include_bias: True 
      bias_learning_rule: Backprop
      bias_learning_rule_kwargs:
        learning_rate: 0.2456298781576449
    SomaI:
      size: 4
      activation: relu

projection_config:
  # H1 Layers (E and SomaI)
  H1.E:
    Input.E:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: exc 
      direction: F
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1

    H1.SomaI:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: inh 
      direction: R
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1
  
  H1.SomaI:
    Input.E:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: exc
      direction: F
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1

    H1.E:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: exc
      direction: R
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1

    H1.SomaI:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: inh
      weight_constraint: no_autapses
      direction: R
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1
  
  # H2 Layers (E and SomaI)
  H2.E:
    H1.E:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: exc
      direction: F
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1

    H2.SomaI:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: inh
      direction: R
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1

  H2.SomaI:
    H1.E:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: exc
      direction: F
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1

    H2.E:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: exc
      direction: R
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1

    H2.SomaI:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: inh
      weight_constraint: no_autapses
      direction: R
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1

  # Output Layers (E and SomaI)
  Output.E:
    H2.E:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: exc
      direction: F
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1

    Output.SomaI:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: inh 
      direction: R
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1

  Output.SomaI:
    H2.E:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: exc
      direction: F
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1

    Output.E:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: exc
      direction: R
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1

    Output.SomaI:
      weight_init: half_kaiming
      weight_init_args: [1.]
      type: inh
      weight_constraint: no_autapses
      direction: R
      learning_rule: Backprop
      learning_rule_kwargs:
          learning_rate: 0.1

training_kwargs:
  tau: 3
  forward_steps: 15
  backward_steps: 3
  learning_rate: 0.2
  verbose: False
  optimizer: SGD