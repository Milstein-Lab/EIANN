bpDale_softplus:
    # 31% final autoenc_CL accuracy
    E_E_learning_rate: 9.999370204719593
    E_I_learning_rate: 9.999150705895477
    I_E_learning_rate: 9.996351412635924
    softplus_beta: 99.98933336685897
bpDale_1_inh_softplus:
    # 29% final autoenc_CL accuracy
    E_E_learning_rate: 9.99769696149066
    E_I_learning_rate: 9.92082657295738
    I_E_learning_rate: 9.999943142695821
    softplus_beta: 98.01406086685208
bpDale_1_inh_static_softplus:
    # 47% final autoenc_CL accuracy
    E_E_learning_rate: 9.99831253932782
    H1_E_H1_FBI_weight_scale: 0.10241322654911048
    H1_FBI_H1_E_weight_scale: 0.1063132002080381
    Output_E_Output_FBI_weight_scale: 2.110604250919318
    Output_FBI_Output_E_weight_scale: 6.250096854022
    softplus_beta: 5.6437800937063365
Gjorgjieva_Hebb_C:
    # 80% autoenc accuracy
    E_I_learning_rate: 0.3786727153452437
    H1_E_H1_FBI_weight_scale: 0.4816625693418726
    H1_E_Input_E_learning_rate: 0.25465177457345606
    H1_E_Input_E_weight_scale: 2.0010743121579004
    H1_FBI_H1_E_weight_scale: 2.700566339617599
    H1_FBI_H1_FBI_weight_scale: 4.829968385994635
    H1_FBI_size: 7.0
    I_E_learning_rate: 0.43530407326954623
    I_I_learning_rate: 0.11482751205962623
    Output_E_H1_E_learning_rate: 0.5150778754781282
    Output_E_H1_E_weight_scale: 8.166940544031512
    Output_E_Output_FBI_weight_scale: 7.161140637799249
    Output_FBI_Output_E_weight_scale: 3.885055613920668
    Output_FBI_Output_FBI_weight_scale: 0.2611915178763533
    Output_FBI_size: 7.0
Supervised_Gjorgjieva_Hebb_C:
    # 100% autoenc accuracy
    # 77% final autoenc_CL accuracy (phase2 0%)
    E_I_learning_rate: 0.08915801057118176
    H1_E_H1_FBI_weight_scale: 1.0130516003908077
    H1_E_Input_E_learning_rate: 0.027806816237176596
    H1_E_Input_E_weight_scale: 6.279900778766666
    H1_FBI_H1_E_weight_scale: 1.3892708878388462
    H1_FBI_H1_FBI_weight_scale: 4.8626043868802915
    H1_FBI_size: 7.0
    I_E_learning_rate: 0.11921699997839098
    I_I_learning_rate: 0.20684912832055066
    Output_E_H1_E_learning_rate: 0.030716245639041958
    Output_E_H1_E_weight_scale: 1.6080949646908016
    Output_E_Output_FBI_weight_scale: 3.141585388118573
    Output_FBI_Output_E_weight_scale: 2.59393042742306
    Output_FBI_Output_FBI_weight_scale: 0.4051025344896375
    Output_FBI_size: 7.0
Gjorgjieva_Hebb_1_inh_static_C:
    # 64% autoenc accuracy
    H1_E_H1_FBI_weight_scale: 0.48371070064980726
    H1_E_Input_E_learning_rate: 0.01986813402764495
    H1_E_Input_E_weight_scale: 1.6403907158557745
    H1_FBI_H1_E_weight_scale: 0.2519187023918979
    Output_E_H1_E_learning_rate: 0.6461520149162121
    Output_E_H1_E_weight_scale: 7.585694360215912
    Output_E_Output_FBI_weight_scale: 3.514615155286358
    Output_FBI_Output_E_weight_scale: 4.590772621218822
Supervised_Gjorgjieva_Hebb_1_inh_static_C:
    # broken - was not optimized with Output.FBI re-equilibration
    # Final H1_E_Input_E weights very close to initial
    # 100% autoenc accuracy
    # 63% final autoenc_CL accuracy (phase2 88%)
    H1_E_H1_FBI_weight_scale: 1.3289354510035343
    H1_E_Input_E_learning_rate: 0.0031106347511018714
    H1_E_Input_E_weight_scale: 1.9413328711772606
    H1_FBI_H1_E_weight_scale: 0.27753630657580225
    Output_E_H1_E_learning_rate: 0.7646357607977765
    Output_E_H1_E_weight_scale: 8.314750366881684
    Output_E_Output_FBI_weight_scale: 3.3943081868830594
    Output_FBI_Output_E_weight_scale: 2.7140699983466927
BTSP_C4:
    # very few plateaus in H1.E
    # 53% final autoenc_CL accuracy (phase2 100%)
    BTSP_neg_loss_ET_discount: 0.06211713037821769
    FB_BTSP_init_weight_factor: 0.3630382775941965
    FF_BTSP_init_weight_factor: 0.7496526208281349
    H1_Dend_I_H1_E_weight_scale: 1.9572784323618608
    H1_E_BTSP_neg_loss_th: -0.42705459786692807
    H1_E_BTSP_pos_loss_th: 0.2245500331456811
    H1_E_H1_Dend_I_init_weight_scale: 1.6866819466750724
    H1_E_H1_Dend_I_learning_rate: 0.024057731673081104
    H1_E_H1_FBI_weight_scale: 0.6797582432156993
    H1_E_Input_E_BTSP_learning_rate: 0.05972690273548245
    H1_E_Input_E_max_weight_scale: 18.640715300844946
    H1_E_Output_E_BTSP_learning_rate: 0.03468283619993962
    H1_E_Output_E_max_weight_scale: 1.467317947897765
    H1_FBI_H1_E_weight_scale: 0.6945095068662492
    Output_E_BTSP_learning_rate: 0.009239016337778882
    Output_E_BTSP_neg_loss_th: -0.07767472344757201
    Output_E_BTSP_pos_loss_th: 0.12127069351058109
    Output_E_H1_E_max_weight_scale: 7.599461850613245
    Output_E_Output_FBI_weight_scale: 1.914128271549981
    Output_FBI_Output_E_weight_scale: 4.634647234572013
BTSP_Clone_Dend_I_1:
    # 80% final autoenc_CL accuracy (phase2 100%)
    BTSP_neg_loss_ET_discount: 0.05308841755118466
    FB_BTSP_init_weight_factor: 0.6520923213097565
    FF_BTSP_init_weight_factor: 0.014336470809976095
    H1_E_BTSP_neg_loss_th: -0.39973873178409025
    H1_E_BTSP_pos_loss_th: 0.1873836122098993
    H1_E_H1_FBI_weight_scale: 0.2684441597880559
    H1_E_Input_E_BTSP_learning_rate: 0.13964634680447138
    H1_E_Input_E_max_weight_scale: 19.98279442204693
    H1_E_Output_E_BTSP_learning_rate: 0.10839844486077162
    H1_E_Output_E_max_weight_scale: 9.493631230540739
    H1_FBI_H1_E_weight_scale: 0.5083794594793958
    Output_E_BTSP_learning_rate: 0.06689802084663056
    Output_E_BTSP_neg_loss_th: -0.16866930555750625
    Output_E_BTSP_pos_loss_th: 0.12302849709209697
    Output_E_H1_E_max_weight_scale: 4.86017837082124
    Output_E_Output_FBI_weight_scale: 3.4258019051236386
    Output_FBI_Output_E_weight_scale: 3.863969708725929
BTSP_C5:
    # broken - BTSP_4 wasn't actually sorting the H1.E units!
    # 76% final autoenc_CL accuracy (phase2 0%)
    # H1.E.plateau amplitude increases over training?!
    BTSP_neg_loss_ET_discount: 0.25060974215626364
    FB_BTSP_init_weight_factor: 0.3506174744876074
    FF_BTSP_init_weight_factor: 0.045139502810390066
    H1_Dend_I_H1_E_weight_scale: 6.864517454213994
    H1_E_BTSP_neg_loss_th: -0.33806511917193216
    H1_E_BTSP_pos_loss_th: 0.0979517612195573
    H1_E_H1_Dend_I_init_weight_scale: 2.2809347830997675
    H1_E_H1_Dend_I_learning_rate: 0.007889704224205549
    H1_E_H1_FBI_weight_scale: 0.32033537996834344
    H1_E_Input_E_BTSP_learning_rate: 0.039752600042183485
    H1_E_Input_E_max_weight_scale: 19.680242173090594
    H1_E_Output_E_BTSP_learning_rate: 0.01817591357761746
    H1_E_Output_E_max_weight_scale: 10.392686532683818
    H1_FBI_H1_E_weight_scale: 3.1445175132258116
    Output_E_BTSP_learning_rate: 0.0076529752996933355
    Output_E_BTSP_neg_loss_th: -0.3361411739484636
    Output_E_BTSP_pos_loss_th: 0.1658100723175087
    Output_E_H1_E_max_weight_scale: 6.268242529048231
    Output_E_Output_FBI_weight_scale: 2.653457299188775
    Output_FBI_Output_E_weight_scale: 3.684906487481957
BTSP_Clone_Dend_I_2:
    # training will be impractically slow on mnist
    # 76% final autoenc_CL accuracy (phase2 100%)
    # very few plateaus in H1.E
    BTSP_neg_loss_ET_discount: 0.07928062024354525
    FB_BTSP_init_weight_factor: 0.5194898323633018
    FF_BTSP_init_weight_factor: 0.6627794889097723
    H1_E_BTSP_neg_loss_th: -0.12191089151620406
    H1_E_BTSP_pos_loss_th: 0.493446945225047
    H1_E_H1_FBI_weight_scale: 0.6829394770237243
    H1_E_Input_E_BTSP_learning_rate: 0.021094172198679942
    H1_E_Input_E_max_weight_scale: 19.172932156328997
    H1_E_Output_E_BTSP_learning_rate: 0.06228842578045147
    H1_E_Output_E_max_weight_scale: 1.76625661001935
    H1_FBI_H1_E_weight_scale: 1.1411259663382092
    Output_E_BTSP_learning_rate: 0.015105919810023028
    Output_E_BTSP_neg_loss_th: -0.06413879410389547
    Output_E_BTSP_pos_loss_th: 0.21780005341902864
    Output_E_H1_E_max_weight_scale: 11.246629974989046
    Output_E_Output_FBI_weight_scale: 2.761603916563075
    Output_FBI_Output_E_weight_scale: 3.478070513878121